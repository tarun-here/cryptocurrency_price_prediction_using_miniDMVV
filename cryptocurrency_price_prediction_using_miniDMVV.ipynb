{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "BNOQkaonQUos"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/content/crypto_prices_180days.csv\")\n",
        "df = df.dropna().reset_index(drop=True)"
      ],
      "metadata": {
        "id": "UKRJbEwKaKPz"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Using only close price\n",
        "y = df[\"close\"].values"
      ],
      "metadata": {
        "id": "SGq0sOS9aKVW"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train/val/test split\n",
        "N = len(y)\n",
        "n_train = int(N * 0.7)\n",
        "n_val   = int(N * 0.15)\n",
        "n_test  = N - n_train - n_val\n",
        "\n",
        "y_train, y_val, y_test = y[:n_train], y[n_train:n_train+n_val], y[n_train+n_val:]"
      ],
      "metadata": {
        "id": "6g2LBXBfaKZr"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Scaling\n",
        "scaler = MinMaxScaler()\n",
        "y_train_2d = y_train.reshape(-1, 1)\n",
        "scaler.fit(y_train_2d)\n",
        "\n",
        "y_train_scaled = scaler.transform(y_train_2d).ravel()\n",
        "y_val_scaled   = scaler.transform(y_val.reshape(-1, 1)).ravel()\n",
        "y_test_scaled  = scaler.transform(y_test.reshape(-1, 1)).ravel()"
      ],
      "metadata": {
        "id": "GF7TeDRMQcpa"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert to torch tensors\n",
        "train_ds = TensorDataset(torch.arange(len(y_train)),\n",
        "                         torch.tensor(y_train, dtype=torch.float32),\n",
        "                         torch.tensor(y_train_scaled, dtype=torch.float32))\n",
        "val_ds   = TensorDataset(torch.arange(len(y_val)),\n",
        "                         torch.tensor(y_val, dtype=torch.float32),\n",
        "                         torch.tensor(y_val_scaled, dtype=torch.float32))\n",
        "test_ds  = TensorDataset(torch.arange(len(y_test)),\n",
        "                         torch.tensor(y_test, dtype=torch.float32),\n",
        "                         torch.tensor(y_test_scaled, dtype=torch.float32))\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size=32, shuffle=True)\n",
        "val_loader   = DataLoader(val_ds, batch_size=32, shuffle=False)\n",
        "test_loader  = DataLoader(test_ds, batch_size=32, shuffle=False)"
      ],
      "metadata": {
        "id": "kQp7Z_B4QiRZ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Model Definition (Mini-DMMV style)\n",
        "class TrendBranch(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(1, 32),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(32, 1)\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        return self.net(x)"
      ],
      "metadata": {
        "id": "M8dcmpRQQmqP"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SeasonalBranch(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(1, 32),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(32, 1)\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        return self.net(x)"
      ],
      "metadata": {
        "id": "l0vEc9aJQpDX"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FusionHead(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.wg = nn.Parameter(torch.tensor(0.0))\n",
        "    def forward(self, trend_out, season_out):\n",
        "        g = torch.sigmoid(self.wg)\n",
        "        return g * season_out + (1 - g) * trend_out"
      ],
      "metadata": {
        "id": "PXTyY8TUSXGI"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trend_branch = TrendBranch().to(DEVICE)\n",
        "season_branch = SeasonalBranch().to(DEVICE)\n",
        "fusion_head = FusionHead().to(DEVICE)\n",
        "\n",
        "loss_fn = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(\n",
        "    list(trend_branch.parameters()) +\n",
        "    list(season_branch.parameters()) +\n",
        "    list(fusion_head.parameters()),\n",
        "    lr=1e-3\n",
        ")"
      ],
      "metadata": {
        "id": "Fa70U04aQrfN"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Training Loop\n",
        "def train_epoch(loader):\n",
        "    trend_branch.train()\n",
        "    season_branch.train()\n",
        "    fusion_head.train()\n",
        "    total_loss = 0.0\n",
        "    for idx, y_orig, y_scaled in loader:\n",
        "        inp = y_scaled.unsqueeze(-1).to(DEVICE)\n",
        "        y_scaled = y_scaled.unsqueeze(-1).to(DEVICE)\n",
        "\n",
        "        trend_pred = trend_branch(inp)\n",
        "        season_pred = season_branch(inp)\n",
        "        pred = fusion_head(trend_pred, season_pred)\n",
        "\n",
        "        loss = loss_fn(pred, y_scaled)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item() * inp.size(0)\n",
        "    return total_loss / len(loader.dataset)"
      ],
      "metadata": {
        "id": "E9X2UDeOQt7B"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Evaluation\n",
        "def eval_model(loader):\n",
        "    trend_branch.eval()\n",
        "    season_branch.eval()\n",
        "    fusion_head.eval()\n",
        "    preds_scaled, trues_scaled, trues_orig = [], [], []\n",
        "    with torch.no_grad():\n",
        "        for idx, y_orig, y_scaled in loader:\n",
        "            inp = y_scaled.unsqueeze(-1).to(DEVICE)\n",
        "            y_scaled = y_scaled.unsqueeze(-1).to(DEVICE)\n",
        "\n",
        "            trend_pred = trend_branch(inp)\n",
        "            season_pred = season_branch(inp)\n",
        "            pred = fusion_head(trend_pred, season_pred)\n",
        "\n",
        "            preds_scaled.extend(pred.cpu().numpy().reshape(-1,1))\n",
        "            trues_scaled.extend(y_scaled.cpu().numpy().reshape(-1,1))\n",
        "            trues_orig.extend(y_orig.numpy().reshape(-1,1))\n",
        "\n",
        "    preds_scaled = np.array(preds_scaled).reshape(-1,1)\n",
        "    trues_scaled = np.array(trues_scaled).reshape(-1,1)\n",
        "    trues_orig   = np.array(trues_orig).reshape(-1,1)\n",
        "\n",
        "    preds_rescaled = scaler.inverse_transform(preds_scaled).ravel()\n",
        "    trues_rescaled = scaler.inverse_transform(trues_scaled).ravel()\n",
        "\n",
        "    mae = mean_absolute_error(trues_orig.ravel(), preds_rescaled)\n",
        "    rmse = math.sqrt(mean_squared_error(trues_orig.ravel(), preds_rescaled))\n",
        "    return mae, rmse, preds_rescaled, trues_orig.ravel()"
      ],
      "metadata": {
        "id": "XvldTn8lQziO"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Training\n",
        "for epoch in range(20):\n",
        "    train_loss = train_epoch(train_loader)\n",
        "    val_mae, val_rmse, _, _ = eval_model(val_loader)\n",
        "    print(f\"Epoch {epoch+1}: Train Loss={train_loss:.6f}, Val MAE={val_mae:.4f}, Val RMSE={val_rmse:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cd52DEnURF6P",
        "outputId": "dfaa1cbe-e3a0-42c6-c9bf-b962719886e9"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Train Loss=0.133552, Val MAE=23224.8008, Val RMSE=23226.4456\n",
            "Epoch 2: Train Loss=0.083952, Val MAE=21871.4453, Val RMSE=21872.5428\n",
            "Epoch 3: Train Loss=0.049592, Val MAE=14566.7998, Val RMSE=14567.7990\n",
            "Epoch 4: Train Loss=0.027483, Val MAE=11188.5098, Val RMSE=11189.2370\n",
            "Epoch 5: Train Loss=0.013274, Val MAE=7311.1221, Val RMSE=7311.6001\n",
            "Epoch 6: Train Loss=0.005498, Val MAE=4360.8755, Val RMSE=4361.2113\n",
            "Epoch 7: Train Loss=0.001839, Val MAE=2304.2878, Val RMSE=2304.5285\n",
            "Epoch 8: Train Loss=0.000505, Val MAE=1094.1233, Val RMSE=1094.3183\n",
            "Epoch 9: Train Loss=0.000118, Val MAE=408.8864, Val RMSE=409.1281\n",
            "Epoch 10: Train Loss=0.000033, Val MAE=131.5609, Val RMSE=132.0636\n",
            "Epoch 11: Train Loss=0.000019, Val MAE=8.8776, Val RMSE=12.4291\n",
            "Epoch 12: Train Loss=0.000016, Val MAE=10.8352, Val RMSE=15.6935\n",
            "Epoch 13: Train Loss=0.000014, Val MAE=10.5615, Val RMSE=15.4274\n",
            "Epoch 14: Train Loss=0.000012, Val MAE=13.0779, Val RMSE=13.4932\n",
            "Epoch 15: Train Loss=0.000010, Val MAE=22.5067, Val RMSE=26.5755\n",
            "Epoch 16: Train Loss=0.000008, Val MAE=50.1482, Val RMSE=52.3269\n",
            "Epoch 17: Train Loss=0.000006, Val MAE=53.0814, Val RMSE=55.2721\n",
            "Epoch 18: Train Loss=0.000005, Val MAE=55.8523, Val RMSE=57.9627\n",
            "Epoch 19: Train Loss=0.000004, Val MAE=12.3423, Val RMSE=16.7385\n",
            "Epoch 20: Train Loss=0.000004, Val MAE=16.3524, Val RMSE=22.5267\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Test Evaluation\n",
        "test_mae, test_rmse, y_pred, y_true = eval_model(test_loader)\n",
        "print(\"Test MAE:\", test_mae, \"Test RMSE:\", test_rmse)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sdiv-bQxRGYh",
        "outputId": "9c5f7644-c255-467e-c1e5-6e28b30c5b49"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test MAE: 37.81850814819336 Test RMSE: 37.818517083235825\n"
          ]
        }
      ]
    }
  ]
}